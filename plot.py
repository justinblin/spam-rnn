import matplotlib.pyplot as plt
from collections import Counter
from dataset import MyDataset
import torch


# currently saved 750 4x model
train_losses = [0.022345484437600923, 0.026480530893343582, 0.01944205602332298, 0.023806724358391294, 0.005586442912658162, 0.009612390752098594, 0.014416106479483147, 0.013160334959084793, 0.02720217224369669, 0.014795571752856092, 0.02179763377174897, 0.02212597146970619, 0.02237122586047198, 0.01644812394261954, 0.02777380113634988, 0.01944089667526544, 0.011415038501525306, 0.021339162409637086, 0.02427121392027359, 0.030791511481584283, 0.01926000726356135, 0.0045501655077794965, 0.0063028407491949896, 0.007494712598819509, 0.013665074060476247, 0.012651395054018438, 0.013038220931302118, 0.01942223053360112, 0.019269891839493455, 0.018302171215988344, 0.021041674330878217, 0.01010964210626162, 0.008168102389747188, 0.01865463138782241, 0.0231796243044968, 0.009659112398318823, 0.022950205181345787, 0.013418343996358098, 0.010610035095823943, 0.005842676767897299]
test_losses = [0.03370918068002048, 0.02462364675827468, 0.023595734346578575, 0.011604223704968818, 0.0054730977387838055, 0.009631575919178983, 0.014300687060969482, 0.012373332339280835, 0.03193288485016474, 0.012898936465597654, 0.021365962045596286, 0.02203046446659616, 0.022176821717732515, 0.013390631417705188, 0.027587984511093334, 0.017936447440239832, 0.011313758146452914, 0.02112304935233351, 0.016895047894480205, 0.030374025203116804, 0.013344993629547181, 0.004468048977030343, 0.009248063268101559, 0.005330645974590309, 0.01345665977300697, 0.012500872652814262, 0.012882488217789678, 0.025172699081446374, 0.024985037614475705, 0.014093322317978383, 0.020730708569815265, 0.004586764700480838, 0.007814113325515713, 0.018338344321870873, 0.022593036469800834, 0.009052954356831129, 0.022746714385283445, 0.012202089921933569, 0.010514265225537228, 0.00584266869944012]      
learning_rates = [0.002, 0.001, 0.002, 0.002, 6.25e-05, 0.00025, 0.002, 0.00025, 0.002, 0.001, 6.25e-05, 6.25e-05, 0.002, 6.25e-05, 6.25e-05, 0.0005, 6.25e-05, 6.25e-05, 0.002, 0.002, 0.002, 6.25e-05, 0.002, 0.0005, 6.25e-05, 6.25e-05, 6.25e-05, 0.002, 0.002, 0.00025, 6.25e-05, 0.001, 0.001, 0.002, 0.000125, 0.0005, 6.25e-05, 0.0005, 6.25e-05, 6.25e-05]

# all_data, flawed
# tensor([[0.8082, 0.0582],
#         [0.0576, 0.0761]], device='cuda:0')
# 88.42152466367713% correct
# precision: 0.5691275000572205
# recall: 0.5664662718772888
# f1 score: 0.5677937865257263

# 3x150, seems decent
train_metrics = ([0.652255203988817, 0.6342407374737172, 0.6018880740335718, 0.5985364061839027, 0.5808357190785003, 0.5729451794109064, 0.5633924114762353, 0.5746148390211029, 0.570231264351731, 0.5466197869328402, 0.5441848978212223, 0.5528529080060811, 0.48581221241217404, 0.4661361678227885, 0.4705338053796464, 0.479475320962371, 0.4723190161019358, 0.4602307953337707, 0.42804504606507404, 0.4279212758436309], [0.524979829788208, 0.5346494913101196, 0.5439161658287048, 0.5471394062042236, 0.5551974773406982, 0.557614803314209, 0.5737308859825134, 0.5688960552215576, 0.5660757422447205, 0.5705076456069946, 0.5866236686706543, 0.5834004878997803, 0.6156325340270996, 0.6208702325820923, 0.6192586421966553, 0.6160354614257812, 0.6188557147979736, 0.6381950378417969, 0.6253021955490112, 0.6244964003562927], [0.4848484992980957, 0.5959595441818237, 0.71875, 0.6785714030265808, 0.7108433842658997, 0.7289156913757324, 0.7457627654075623, 0.747619092464447, 0.7650273442268372, 0.7783504724502563, 0.8162392973899841, 0.7611940503120422, 0.7941176891326904, 0.8041775822639465, 0.7898734211921692, 0.7870129942893982, 0.7676056027412415, 0.8382352590560913, 0.81937175989151, 0.80402010679245], [0.0681430995464325, 0.050255533307790756, 0.05877342447638512, 0.08091992884874344, 0.10051106661558151, 0.10306644439697266, 0.14991481602191925, 0.13373082876205444, 0.11925042420625687, 0.12862010300159454, 0.1626916378736496, 0.1737648993730545, 0.2529812455177307, 0.2623509168624878, 0.26575809717178345, 0.2580919861793518, 0.2785349190235138, 0.29131177067756653, 0.26660987734794617, 0.27257239818573], [0.11949215728283558, 0.09269441635151814, 0.10866141781091719, 0.14459664606341227, 0.17611939312484767, 0.1805970232894092, 0.2496453859962436, 0.22687860616013228, 0.20633750747820373, 0.22076023334718747, 0.2713067968445612, 0.28294035283664426, 0.38372091774025247, 0.3956326084113282, 0.3977055511717386, 0.38871070493608323, 0.408749990949314, 0.43236410903152395, 0.4023136246803371, 0.4071246784360747])
test_metrics = ([0.5614866725600101, 0.5730750632082295, 0.5530258825865275, 0.5228979227670968, 0.5077493270456573, 0.5126121890286531, 0.5279115758863561, 0.5405954945109265, 0.4954031534465676, 0.49232334597206834, 0.5463089642179754, 0.4726269756135632, 0.44284917981851674, 0.4465390364474574, 0.43505743017672605, 0.5618762968333213, 0.45142968948725826, 0.4167984877604995, 0.3849568341077465, 0.3965559206693746], [0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8653321266174316, 0.8732180595397949, 0.8531998991966248, 0.8680618405342102, 0.8713982701301575, 0.8644222021102905, 0.7291476726531982, 0.8322717547416687, 0.8525933027267456, 0.8407643437385559, 0.8522899746894836, 0.768577516078949, 0.8507734537124634, 0.8562329411506653, 0.8474370241165161, 0.8468304872512817], [0, 0, 0, 0, 0.402515709400177, 0.42424246668815613, 0.3514644503593445, 0.4236110746860504, 0.4476190507411957, 0.4279661178588867, 0.22850680351257324, 0.34375, 0.3977590799331665, 0.36915889382362366, 0.3989071249961853, 0.25895318388938904, 0.3957783579826355, 0.40378549695014954, 0.3815789520740509, 0.37958115339279175], [0.0, 0.0, 0.0, 0.0, 0.1549636870622635, 0.033898308873176575, 0.20338983833789825, 0.1476997584104538, 0.11380145698785782, 0.24455206096172333, 0.48910412192344666, 0.37288135290145874, 0.34382566809654236, 0.3825666010379791, 0.35351091623306274, 0.4552058279514313, 0.36319613456726074, 0.309927374124527, 0.35108959674835205, 0.35108959674835205], [0, 0, 0, 0, 0.22377622859228477, 0.06278027602015179, 0.2576687220277066, 0.21903051637234983, 0.18146718706775092, 0.31124808054325004, 0.3114880655353545, 0.35772357584109693, 0.36883115992565746, 0.37574317811063424, 0.37483955865522034, 0.3301141525027827, 0.378787880688153, 0.35068494306650405, 0.3656998805985622, 0.3647798794524248])
learning_rates = [0.05333333333333334, 0.05333333333333334, 0.05333333333333334, 0.035888888888888894, 0.035888888888888894, 0.035888888888888894, 0.0345925925925926, 0.0345925925925926, 0.0345925925925926, 0.0237283950617284, 0.0237283950617284, 0.0237283950617284, 0.0171522633744856, 0.0171522633744856, 0.0171522633744856, 0.0171522633744856, 0.0171522633744856, 0.0171522633744856, 0.0117681755829904, 0.0117681755829904]

# 4x150
train_metrics = ([0.6792096006564604, 0.6414061470103545, 0.6131820318220493, 0.5923563706763256, 0.6197007696561615, 0.5925955237971606, 0.5929746375270231, 0.5753932219964486, 0.5738064956873667, 0.5616911672628843, 0.5498152208925021, 0.550483492959259, 0.5549277785011651, 0.544423129544493, 0.5466362813962975, 0.5188773301349309, 0.4776892469067083, 0.4564097642922819, 0.4448436382804695, 0.4509417410541172], [0.5261885523796082, 0.5298147201538086, 0.5515713095664978, 0.5406929850578308, 0.5443190932273865, 0.5539886951446533, 0.5535858273506165, 0.548348069190979, 0.5564061403274536, 0.5564061403274536, 0.5697019100189209, 0.5616438388824463, 0.5725221633911133, 0.5817888975143433, 0.5769540667533875, 0.5922642946243286, 0.6305398941040039, 0.6228847503662109, 0.6257050633430481, 0.6176470518112183], [0.4967948794364929, 0.5714285969734192, 0.756302535533905, 0.6231883764266968, 0.6080402135848999, 0.7005987763404846, 0.6875, 0.6480446457862854, 0.7385620474815369, 0.7039105892181396, 0.7623762488365173, 0.7107843160629272, 0.7756097912788391, 0.7931034564971924, 0.7348484992980957, 0.7664473652839661, 0.805225670337677, 0.7931033968925476, 0.810126543045044, 0.7862595915794373], [0.132027268409729, 0.023850085213780403, 0.07666098326444626, 0.07325383275747299, 0.10306644439697266, 0.0996592789888382, 0.10306644439697266, 0.09880749136209488, 0.09625212848186493, 0.10732537508010864, 0.1311754584312439, 0.12350936979055405, 0.13543440401554108, 0.15672913193702698, 0.16524702310562134, 0.19846677780151367, 0.288756400346756, 0.2742759585380554, 0.27257239818573, 0.2632027268409729], [0.20861374274616332, 0.04578904348239765, 0.13921112920542883, 0.13109755985823732, 0.17625638056160348, 0.1744966350431103, 0.17925926663120093, 0.1714707973796928, 0.1703089648758878, 0.1862527583476867, 0.223837195150151, 0.21044992769934387, 0.23060187501996096, 0.26173542113978365, 0.2698192001185809, 0.3152909303535682, 0.42507838522077857, 0.4075949067138094, 0.4079031137144817, 0.39438418107295203])
test_metrics = ([0.6486496282912, 0.547097012127712, 0.5775079619826268, 0.685335226129554, 0.5044887672122725, 0.5084811809662642, 0.5030794564238836, 0.5045576248868335, 0.5035964302054545, 0.49444985320571005, 0.49264484712164897, 0.48094948996154085, 0.47684541496565347, 0.4837821266262523, 0.49752838980583924, 0.4536021689410174, 0.4177897147224791, 0.42212465213513933, 0.4007417040266397, 0.47641795315075847], [0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8717015385627747, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.874127984046936, 0.874127984046936, 0.8738247156143188, 0.8701850175857544, 0.8720048069953918, 0.8510767221450806, 0.8462238311767578, 0.8231725692749023, 0.8067940473556519, 0.855019748210907, 0.8565362691879272, 0.8252956867218018, 0.8152866363525391], [0, 0, 0, 0.4404761791229248, 0, 0, 0, 0.375, 0.375, 0.3333333134651184, 0.4390243589878082, 0.4628099203109741, 0.3586956560611725, 0.34228187799453735, 0.3199152648448944, 0.2971014380455017, 0.3987538814544678, 0.4013157784938812, 0.3305613398551941, 0.3100775182247162], [0.0, 0.0, 0.0, 0.08958838135004044, 0.0, 0.0, 0.0, 0.007263922598212957, 0.007263922598212957, 0.007263922598212957, 0.1307506114244461, 0.1355932354927063, 0.23970945179462433, 0.24697336554527283, 0.36561742424964905, 0.3970944285392761, 0.309927374124527, 0.2953995168209076, 0.38498789072036743, 0.3874092102050781], [0, 0, 0, 0.14889336452021096, 0, 0, 0, 0.0142517816267634, 0.0142517816267634, 0.014218009613949152, 0.20149254126185417, 0.20973784614757068, 0.2873730118502158, 0.28691983075329625, 0.3412429398960535, 0.33989636480921864, 0.34877384558499996, 0.34030683080134333, 0.3557047021968977, 0.3444564076745137])
learning_rates = [0.05333333333333334, 0.05333333333333334, 0.05333333333333334, 0.04088888888888889, 0.04088888888888889, 0.04088888888888889, 0.0325925925925926, 0.0325925925925926, 0.0325925925925926, 0.023061728395061733, 0.023061728395061733, 0.023061728395061733, 0.016707818930041154, 0.016707818930041154, 0.016707818930041154, 0.012471879286694104, 0.012471879286694104, 0.012471879286694104, 0.012471879286694104, 0.012471879286694104]

train_metrics = ([0.6362465978348018, 0.5546554123598431, 0.569201021537482, 0.5606835217411845, 0.5487838461237027, 0.5644469701836251, 0.5080347945280661, 0.5324187275715169, 0.5374624981815173, 0.493145472073293, 0.47682192794278133, 0.45821660640621065, 0.4555725278313877, 0.4893413749127353, 0.48019432234337156, 0.49125460447651814, 0.49623860660781194, 0.43524842285678117, 0.4863955095671132, 0.41085754636346106], [0.5273972749710083, 0.5688960552215576, 0.5644641518592834, 0.5688960552215576, 0.5584205985069275, 0.5705076456069946, 0.5970991253852844, 0.5922642946243286, 0.5749395489692688, 0.5970991253852844, 0.591861367225647, 0.6176470518112183, 0.6228847503662109, 0.6067687273025513, 0.612006425857544, 0.6087832450866699, 0.5995165109634399, 0.6103948354721069, 0.5970991253852844, 0.6059629321098328], [0.5012285113334656, 0.6511628031730652, 0.6049661040306091, 0.6925925612449646, 0.6308724880218506, 0.6120331883430481, 0.7111650109291077, 0.6505576372146606, 0.5939968228340149, 0.6726190447807312, 0.6639511585235596, 0.7622377872467041, 0.7609649300575256, 0.7426470518112183, 0.7089108824729919, 0.698630154132843, 0.7083333730697632, 0.7074148654937744, 0.7061610817909241, 0.7663043141365051], [0.1737648993730545, 0.19080068171024323, 0.22827938199043274, 0.15928450226783752, 0.16013628244400024, 0.2512776851654053, 0.24957410991191864, 0.2981260418891907, 0.3202725648880005, 0.288756400346756, 0.2776831388473511, 0.2785349190235138, 0.2955707013607025, 0.2580919861793518, 0.3049403727054596, 0.3040885925292969, 0.26064735651016235, 0.3006814122200012, 0.2538330554962158, 0.24020443856716156], [0.25806450982566387, 0.29512516630574087, 0.33147803539323306, 0.25900277426744706, 0.2554347782225448, 0.35628019414662854, 0.3694829756651514, 0.4088784864240498, 0.41615936952318944, 0.40405245455338556, 0.39159160250411834, 0.40798502702529676, 0.42576687695063065, 0.3830594098079012, 0.4264443084961622, 0.4237388818668695, 0.3810709864139393, 0.4219964015033951, 0.37343358277174477, 0.3657587617679591])
test_metrics = ([0.4341990429457727, 0.5034244027129751, 0.4198009693160452, 0.4740627521378362, 0.42435995711329794, 0.4596230207381813, 0.5201854063914374, 0.5067220550389808, 0.5449410409499437, 0.3670754334246865, 0.3758261813730985, 0.3570493412350778, 0.5631112404831746, 0.37, 0.3655091238564042, 0.36863628250884484, 0.5199948000347513, 0.4273865162070854, 0.36318140411897293, 0.3721899653401713], [0.8528965711593628, 0.8389444947242737, 0.8325750827789307, 0.8589626550674438, 0.7758568525314331, 0.8471338152885437, 0.8516833186149597, 0.8489536046981812, 0.7230815887451172, 0.8565362691879272, 0.854716420173645, 0.8474370837211609, 0.7755535244941711, 0.30906885862350464, 0.8471337556838989, 0.8092204928398132, 0.8007279634475708, 0.8398544192314148, 0.8422808647155762, 0.840461015701294], [0.37142854928970337, 0.35175880789756775, 0.3194805383682251, 0.36734694242477417, 0.262390673160553, 0.32958802580833435, 0.36713284254074097, 0.3684210479259491, 0.2228381484746933, 0.4038461744785309, 0.4073033630847931, 0.38461539149284363, 0.2375601977109909, 0.140377938747406, 0.38242894411087036, 0.303636372089386, 0.2896551787853241, 0.36406615376472473, 0.3691931664943695, 0.36515510082244873], [0.2518160045146942, 0.33898305892944336, 0.2978208363056183, 0.17433415353298187, 0.4358353614807129, 0.21307507157325745, 0.2542372941970825, 0.2881355881690979, 0.48668283224105835, 0.305084764957428, 0.35108959674835205, 0.36319613456726074, 0.35835352540016174, 0.8813559412956238, 0.35835352540016174, 0.4043583869934082, 0.4067796766757965, 0.37288135290145874, 0.36561742424964905, 0.37046003341674805], [0.30014430988249513, 0.34525278525314695, 0.3082706924813386, 0.23645321477324138, 0.3275705236194825, 0.2588235408954554, 0.30042918054758166, 0.3233695602237462, 0.30570343704738184, 0.3475862269962869, 0.37711313546779024, 0.3735990115617636, 0.28571429400901405, 0.24218229963490867, 0.37000000938912847, 0.34683283195387765, 0.3383685898252459, 0.36842103062549225, 0.36739659521664836, 0.3677884387000484])
learning_rates = [0.043000000000000003, 0.043000000000000003, 0.043000000000000003, 0.029, 0.029, 0.029, 0.03, 0.03, 0.03, 0.030666666666666665, 0.030666666666666665, 0.030666666666666665, 0.030666666666666665, 0.030666666666666665, 0.030666666666666665, 0.025777777777777778, 0.025777777777777778, 0.025777777777777778, 0.025777777777777778, 0.025777777777777778]

# 5x130, reduce dropout 0.15,0.15,0.15,0.15,0.4
# definately some overfitting in second run
train_metrics = ([0.648388710675028, 0.6203004493672624, 0.561125823308357, 0.5664354906268462, 0.5461768000335484, 0.5599058350266894, 0.559334251191202, 0.5309417462101496, 0.5077835096665694, 0.49528392339121485, 0.48093037543182315, 0.4986232742333635, 0.5207348187303561, 0.4590823701910726, 0.44713061862376163, 0.4567202475554195, 0.4681207248482414, 0.4260092428242913, 0.38076709645110807, 0.3666614858319131], [0.5273972749710083, 0.5286059379577637, 0.534246563911438, 0.5334408283233643, 0.5362610816955566, 0.5439161658287048, 0.5410959124565125, 0.5539887547492981, 0.5427075028419495, 0.5600321888923645, 0.5962933301925659, 0.5878323912620544, 0.565269947052002, 0.5870265960693359, 0.5995165109634399, 0.6083803176879883, 0.6124093532562256, 0.6410152912139893, 0.6555197238922119, 0.6498791575431824], [1.0, 0.75, 0.604651153087616, 0.5540540814399719, 0.5891472697257996, 0.6117021441459656, 0.6576576828956604, 0.6936416625976562, 0.6291390657424927, 0.7252748012542725, 0.8185185194015503, 0.7412140369415283, 0.6848248839378357, 0.7670250535011292, 0.7694610357284546, 0.7774725556373596, 0.7409090995788574, 0.7881873846054077, 0.8073217868804932, 0.7747747898101807], [0.0008517887908965349, 0.0051107327453792095, 0.04429301619529724, 0.06984667479991913, 0.06473594903945923, 0.09795571118593216, 0.06218057870864868, 0.10221465677022934, 0.08091992884874344, 0.11243611574172974, 0.18824531137943268, 0.19761498272418976, 0.14991481602191925, 0.18228277564048767, 0.21890971064567566, 0.24105623364448547, 0.2776831388473511, 0.32964223623275757, 0.3568994998931885, 0.36626917123794556], [0.001702127728473282, 0.01015228467247041, 0.08253968394787793, 0.12405445853643379, 0.11665388110655166, 0.1688693167096811, 0.1136186765718771, 0.17817372995232042, 0.14339622150735526, 0.19469026807197398, 0.3060941778868831, 0.3120376469770424, 0.24598182280709213, 0.2945629466985505, 0.3408488025417073, 0.36801042443982135, 0.40396530939505354, 0.46486485451505277, 0.4949793398624479, 0.49739734812523917])
test_metrics = ([0.543245248851322, 0.44225505669402254, 0.4734155241586494, 0.3964655896664684, 0.38983178963846055, 0.686771129568418, 0.3777097881986543, 0.46401103557757256, 0.40030874569373837, 0.3771104469476893, 0.37303088327030565, 0.36231865242614847, 0.4004395057484779, 0.3670495949976683, 0.4045331700544654, 0.3808948784902855, 0.36484678775545143, 0.31415975592366363, 0.2976347088622742, 0.45610091649678164], [0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8747345805168152, 0.8632089495658875, 0.8377312421798706, 0.8747345805168152, 0.8507734537124634, 0.7849559783935547, 0.8080072999000549, 0.8553230166435242, 0.8422808647155762, 0.8468304872512817, 0.8322718143463135], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.40952378511428833, 0.35406696796417236, 0, 0.3806646764278412, 0.2764350175857544, 0.304270476102829, 0.4080459773540497, 0.3729216456413269, 0.38265305757522583, 0.3484848439693451], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20823244750499725, 0.35835352540016174, 0.0, 0.305084764957428, 0.4430992901325226, 0.4140436053276062, 0.34382566809654236, 0.38014528155326843, 0.36319613456726074, 0.38983049988746643], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.27608346329194644, 0.3561973508047862, 0, 0.3387096986939756, 0.3404651001241142, 0.35076924753997923, 0.37319316834666316, 0.37649881799416207, 0.3726708102812162, 0.36799999365615843])
learning_rates = [0.05333333333333334, 0.05333333333333334, 0.05333333333333334, 0.03822222222222222, 0.03822222222222222, 0.03822222222222222, 0.030814814814814812, 0.030814814814814812, 0.030814814814814812, 0.030814814814814812, 0.030814814814814812, 0.030814814814814812, 0.02187654320987654, 0.02187654320987654, 0.02187654320987654, 0.02187654320987654, 0.02187654320987654, 0.02187654320987654, 0.025251028806584364, 0.025251028806584364] 

train_metrics = ([0.4805739090228691, 0.4875094240935391, 0.6329264090368792, 0.585724126640063, 0.4362772130776965, 0.3695508764194773, 0.4113616457873843, 0.3923933642469483, 0.386499904193163, 0.40437373853113096, 0.34311609078421557, 0.33717031045492757, 0.3446490440273556, 0.28591254737423744, 0.32485987568076263, 0.28072122715210407, 0.2963707871707804, 0.2692624931055013, 0.29338592051319534, 0.29939821183584453], [0.6281224489212036, 0.6152296662330627, 0.5302175879478455, 0.5423046350479126, 0.6204673647880554, 0.6466559171676636, 0.6289283037185669, 0.6454472541809082, 0.655116856098175, 0.6281225085258484, 0.6394037008285522, 0.6422240138053894, 0.6651893854141235, 0.667606770992279, 0.6385979056358337, 0.664383590221405, 0.6663980484008789, 0.6708299517631531, 0.667606770992279, 0.6555197238922119], [0.6698241233825684, 0.6394904255867004, 0.5051282048225403, 0.5340501666069031, 0.6823899745941162, 0.7274119853973389, 0.683068037033081, 0.72826087474823, 0.7484374642372131, 0.683748185634613, 0.7313432693481445, 0.7241379618644714, 0.7962003350257874, 0.8132854700088501, 0.7160686254501343, 0.8083183169364929, 0.8168498277664185, 0.8082901239395142, 0.8045375347137451, 0.7511810660362244], [0.4216354191303253, 0.42759793996810913, 0.3356047570705414, 0.2538330554962158, 0.3696763217449188, 0.404599666595459, 0.40204429626464844, 0.3994889259338379, 0.40800681710243225, 0.39778533577919006, 0.37563881278038025, 0.3935264050960541, 0.39267462491989136, 0.38586029410362244, 0.39097100496292114, 0.38074958324432373, 0.3798977732658386, 0.3986371159553528, 0.39267462491989136, 0.4063032269477844], [0.5175117610970461, 0.5125063629909052, 0.40327532320662374, 0.34411085748530174, 0.47955802154557, 0.5199781225770929, 0.5061662278139264, 0.5159515957827714, 0.5281146571625528, 0.5029617598084839, 0.4963421212827955, 0.5099337821801984, 0.5259555099581341, 0.523396871405508, 0.5057850910182826, 0.5176607025646257, 0.5186046421039483, 0.5339417873947564, 0.5277618877081407, 0.5273631668310013])
test_metrics = ([0.28005264875944136, 0.6070147653602709, 0.5238894106449516, 0.37638993297449985, 0.31330947509724577, 0.32083846491071255, 1.0052459248511056, 0.3283730739834508, 0.3323257379006409, 0.22666353548584695, 0.220238334573214, 0.24355954481959718, 0.2735772651525826, 0.242243449218453, 0.2878957261969318, 0.2438294564525032, 0.24057151375836502, 0.34686986445216195, 0.24399759243350466, 0.6647899959859538], [0.8465271592140198, 0.6029723882675171, 0.8704882860183716, 0.8698817491531372, 0.8334850072860718, 0.8410676717758179, 0.5859872698783875, 0.8525933027267456, 0.8562329411506653, 0.8380345702171326, 0.8383378386497498, 0.840461015701294, 0.8237792253494263, 0.8362147808074951, 0.8428874611854553, 0.84804368019104, 0.8462238311767578, 0.8422808647155762, 0.8337883353233337, 0.5741583108901978], [0.3822785019874573, 0.1309719979763031, 0.36000001430511475, 0.40909090638160706, 0.34753361344337463, 0.36496350169181824, 0.1721763163805008, 0.3977590799331665, 0.4061538279056549, 0.3596287667751312, 0.35576921701431274, 0.36385542154312134, 0.3299594819545746, 0.3546910881996155, 0.3614775836467743, 0.3842105269432068, 0.3788659870624542, 0.3685503602027893, 0.3503325879573822, 0.1750819832086563], [0.36561742424964905, 0.38498789072036743, 0.04358353838324547, 0.08716707676649094, 0.37530267238616943, 0.36319613456726074, 0.6053268909454346, 0.34382566809654236, 0.319612592458725, 0.37530267238616943, 0.35835352540016174, 0.36561742424964905, 0.39467310905456543, 0.37530267238616943, 0.33171913027763367, 0.35351091623306274, 0.35593220591545105, 0.36319613456726074, 0.3825666010379791, 0.646489143371582], [0.3737623814743383, 0.19545175642121398, 0.07775378524184544, 0.14371258358335418, 0.36088474368614626, 0.36407767327942875, 0.2680965256657905, 0.36883115992565746, 0.3577235711974317, 0.3672985806449531, 0.3570566950854472, 0.3647342948846602, 0.3594266562691855, 0.3647058932834018, 0.34595960209714566, 0.36822195331965624, 0.36704120344925484, 0.3658536588168795, 0.3657407442118014, 0.2755418190400765])
learning_rates = [0.044000000000000004, 0.044000000000000004, 0.044000000000000004, 0.030000000000000002, 0.030000000000000002, 0.030000000000000002, 0.030000000000000002, 0.030000000000000002, 0.030000000000000002, 0.02066666666666667, 0.02066666666666667, 0.02066666666666667, 0.02066666666666667, 0.02066666666666667, 0.02066666666666667, 0.014444444444444447, 0.014444444444444447, 0.014444444444444447, 0.014444444444444447, 0.014444444444444447]

# 6x120?, increase weight decay
# whole bunch of overfitting, definately need more
# dropout 0.2 x 5, 0.4
train_metrics = ([0.5074277785574463, 0.47025492434391025, 0.3320802411001584, 0.31638010738945904, 0.2912370610222566, 0.33074853206292176, 0.2716895764375975, 0.24457679826600986, 0.2896197125631035, 0.2871691692722101, 0.27646579752923706, 0.26652786564453373, 0.25776129953736054, 0.2829655414014315, 0.26333514756250537, 0.2688959915225808, 0.2695707235520187, 0.9437212907156908, 0.33225224499155165, 0.2455750805457336], [0.6297340989112854, 0.6353747248649597, 0.6498791575431824, 0.6422240138053894, 0.6611603498458862, 0.6470588445663452, 0.6494762301445007, 0.6655923128128052, 0.6430298089981079, 0.6450443267822266, 0.6490733623504639, 0.6539081335067749, 0.6559226512908936, 0.6563255190849304, 0.6623690724372864, 0.6611603498458862, 0.6692183613777161, 0.5298146605491638, 0.6216760873794556, 0.6631748676300049], [0.7232924699783325, 0.6975036859512329, 0.7757685780525208, 0.760948896408081, 0.7798319458961487, 0.7670250535011292, 0.7585034370422363, 0.8185185194015503, 0.7618181705474854, 0.7855750918388367, 0.7739601731300354, 0.7748691439628601, 0.7768166065216064, 0.7551670074462891, 0.7649842500686646, 0.804387629032135, 0.7824000120162964, 0.5032080411911011, 0.7537797093391418, 0.8072726726531982], [0.351788729429245, 0.404599666595459, 0.36541739106178284, 0.35519590973854065, 0.3952299952507019, 0.36456558108329773, 0.3798977732658386, 0.37649062275886536, 0.3568994998931885, 0.343270868062973, 0.36456558108329773, 0.3781941831111908, 0.38245314359664917, 0.404599666595459, 0.41311752796173096, 0.37478703260421753, 0.4165246784687042, 0.467631995677948, 0.29727426171302795, 0.3781941831111908], [0.4733524112590384, 0.5121293899212894, 0.49681530886622266, 0.4843205541713571, 0.5245901777264051, 0.4942263143381003, 0.506242903007544, 0.5157526185147573, 0.486078894187557, 0.4777711986985779, 0.4956571938900752, 0.5082999277459139, 0.5125570698829385, 0.5268996364102466, 0.5365044144935865, 0.5113306151442186, 0.5436353359395183, 0.4847681834430281, 0.4263897245233506, 0.5150811724469561])
test_metrics = ([0.4115752949310019, 0.27937173693735373, 0.2518422843635956, 0.301614830850354, 0.21019450033831802, 0.3493733407249527, 0.261117910995843, 0.23610219744890387, 0.22921209743244164, 0.24942497636608887, 0.23852269003060853, 0.2253976380805029, 0.2841104593137064, 0.32840923953605805, 0.23307057251068922, 0.2604402122753006, 1, 0.44376342394303936, 0.22540205861049475, 0.23547386422625974], [0.8346982002258301, 0.8489536046981812, 0.8434940576553345, 0.8016378879547119, 0.8416742086410522, 0.84804368019104, 0.8416742086410522, 0.8428874611854553, 0.8359114527702332, 0.8374279737472534, 0.8483469486236572, 0.8434940576553345, 0.8444039821624756, 0.8492568731307983, 0.848347008228302, 0.8507733941078186, 0.3281771242618561, 0.7455262541770935, 0.8425841331481934, 0.8434941172599792], [0.3539822995662689, 0.38786280155181885, 0.3728395104408264, 0.29401710629463196, 0.36867469549179077, 0.38359788060188293, 0.3705463409423828, 0.37288135290145874, 0.353881299495697, 0.3599088788032532, 0.38817480206489563, 0.3759036362171173, 0.37562188506126404, 0.37931033968925476, 0.38874679803848267, 0.391780823469162, 0.13902242481708527, 0.24213075637817383, 0.3700980246067047, 0.37530267238616943], [0.3874092102050781, 0.35593220591545105, 0.36561742424964905, 0.4164648950099945, 0.37046003341674805, 0.35108959674835205, 0.3777239918708801, 0.37288135290145874, 0.37530267238616943, 0.3825666010379791, 0.36561742424964905, 0.3777239918708801, 0.36561742424964905, 0.319612592458725, 0.36803874373435974, 0.34624695777893066, 0.8401936888694763, 0.48426151275634766, 0.36561742424964905, 0.37530267238616943], [0.36994220002287265, 0.3712121247465099, 0.3691931514544237, 0.3446893885539418, 0.3695652082631302, 0.3666245291120845, 0.37410074123260534, 0.37288135290145874, 0.3642773361171525, 0.37089202319945536, 0.37655859621551, 0.37681161554796255, 0.3705521398630853, 0.34691195677870346, 0.3781094518419942, 0.3676092463969755, 0.23856993836201268, 0.32284100850423175, 0.36784408071606584, 0.37530267238616943])
learning_rates = [0.04533333333333334, 0.04533333333333334, 0.04533333333333334, 0.030555555555555558, 0.030555555555555558, 0.030555555555555558, 0.02303703703703704, 0.02303703703703704, 0.02303703703703704, 0.02303703703703704, 0.02303703703703704, 0.02303703703703704, 0.018024691358024692, 0.018024691358024692, 0.018024691358024692, 0.02268312757201646, 0.02268312757201646, 0.02268312757201646, 0.016455418381344306, 0.016455418381344306] 

# 10x100? try if it works
# bit bumpy but seems to work
train_metrics = ([0.5509455508886435, 0.3558737881296671, 0.42963568349230524, 0.4560393615253193, 0.6181568593138547, 0.5154319423992652, 0.37214235898970005, 0.40072927824428134, 0.5923367098798633, 0.3803902657707871, 0.3113193182706057, 0.2838395569302175, 0.3246312919105026, 0.43082303573530184, 0.41798954832151153, 0.29024755590855716, 0.27015383035781476, 0.25938701476503007, 0.23427884545712438, 0.24646570616904726], [0.6015310287475586, 0.613618016242981, 0.6148267984390259, 0.6333601474761963, 0.5511683821678162, 0.5688960552215576, 0.6265108585357666, 0.6188557744026184, 0.5813859701156616, 0.6083803176879883, 0.6510878801345825, 0.6607574224472046, 0.6373891830444336, 0.6140209436416626, 0.5995165109634399, 0.6446413993835449, 0.6547139286994934, 0.667606770992279, 0.6587429642677307, 0.6668009757995605], [0.6489532589912415, 0.6979742050170898, 0.716269850730896, 0.7382671236991882, 0.5401069521903992, 0.5966542959213257, 0.7193605303764343, 0.6965517401695251, 0.5946704149246216, 0.7224669456481934, 0.7759856581687927, 0.8029196858406067, 0.7584905624389648, 0.662162184715271, 0.7195122241973877, 0.7931726574897766, 0.7876588106155396, 0.8024263381958008, 0.7956600189208984, 0.8126125931739807], [0.343270868062973, 0.32282793521881104, 0.30749574303627014, 0.3483816087245941, 0.34412264823913574, 0.2734241783618927, 0.34497442841529846, 0.34412264823913574, 0.36115843057632446, 0.2793866991996765, 0.3688245415687561, 0.37478703260421753, 0.3424190878868103, 0.37563881278038025, 0.2512776851654053, 0.3364565372467041, 0.3696763217449188, 0.3943782150745392, 0.37478703260421753, 0.384156733751297], [0.44902505889991723, 0.4414676704921228, 0.4302741395215639, 0.4733796314272001, 0.42039541456165047, 0.3749999924151178, 0.4663212191636676, 0.46066134063172165, 0.44939056772614516, 0.40294838724905996, 0.5000000082173399, 0.5110336584868687, 0.4718309926418552, 0.4793478085581615, 0.3724747536018446, 0.47248801114781946, 0.5031884088828318, 0.5288406801623774, 0.5095541179152265, 0.521688837732685])
test_metrics = ([0.25636920054535284, 0.30574154791050345, 0.313143219803352, 0.2812842809741859, 0.45083165478065906, 0.278747082475268, 0.6632800309194458, 0.26656803193983136, 0.3619146353141002, 0.34403477676476607, 0.24648577170457892, 0.22002919839287996, 0.29721181761014015, 0.36604218507897435, 0.2630587983762752, 0.26511458856518744, 0.2878062538256793, 0.22121063833862945, 0.263334503517883, 0.24534193340857244], [0.827115535736084, 0.8101304173469543, 0.8474370837211609, 0.8501668572425842, 0.874127984046936, 0.8131634593009949, 0.6511980891227722, 0.848650336265564, 0.8240824937820435, 0.7546254396438599, 0.827115535736084, 0.8450106382369995, 0.7779800295829773, 0.8419775366783142, 0.8161965608596802, 0.814073383808136, 0.8310585618019104, 0.8441006541252136, 0.8501667976379395, 0.8431907892227173], [0.3388090431690216, 0.3016759753227234, 0.3840206265449524, 0.38904109597206116, 0.4861110746860504, 0.3059273362159729, 0.19266057014465332, 0.383783757686615, 0.2875318229198456, 0.24873097240924835, 0.3311827778816223, 0.37371134757995605, 0.2650957405567169, 0.32692307233810425, 0.31041255593299866, 0.31060606241226196, 0.3392857313156128, 0.372795969247818, 0.39083558320999146, 0.371921181678772], [0.3995157480239868, 0.3922518193721771, 0.36077481508255005, 0.34382566809654236, 0.08474576473236084, 0.3874092102050781, 0.5593220591545105, 0.34382566809654236, 0.2736077606678009, 0.47457626461982727, 0.37288135290145874, 0.35108959674835205, 0.4358353614807129, 0.24697336554527283, 0.3825666010379791, 0.3970944285392761, 0.36803874373435974, 0.35835352540016174, 0.35108959674835205, 0.36561742424964905], [0.36666667551619037, 0.34105263137137126, 0.37203495828840283, 0.3650385617080147, 0.14432989823196107, 0.34188034170522125, 0.2866005213753927, 0.3627075247112787, 0.28039703664049825, 0.3263946763925254, 0.35079725517847726, 0.3620474486101068, 0.3296703415690755, 0.28137930859975097, 0.3427331839585828, 0.3485653561963629, 0.35307782700879836, 0.3654321060544413, 0.3698979654843558, 0.3687423637928873])
learning_rates = [0.04533333333333334, 0.04533333333333334, 0.04533333333333334, 0.051555555555555556, 0.051555555555555556, 0.051555555555555556, 0.0357037037037037, 0.0357037037037037, 0.0357037037037037, 0.024469135802469136, 0.024469135802469136, 0.024469135802469136, 0.024469135802469136, 0.024469135802469136, 0.024469135802469136, 0.016646090534979424, 0.016646090534979424, 0.016646090534979424, 0.016646090534979424, 0.016646090534979424]

# 10x300 with more dropout and weight decay

# Main problems right now is loss plateauing, overfitting (test f1 < train f1), and the training precision/recall gap
# Going forward, increase complexity to reduce plateauing, use weight decay/dropout to prevent overfitting, idk about precision/recall gap

# increase number of layers, switch optimizer to Adam?, overregulation?

plt.figure()
# plot all the training metrics
for i in range(len(train_metrics)):
    # if i != 0 and i != 1:
    if i != 1 and i != 2 and i != 3:
        plt.plot(train_metrics[i])

# plot all the testing metrics
for i in range(len(test_metrics)):
    # if i != 0 and i != 1:
    if i != 1 and i != 2 and i != 3:
        plt.plot(test_metrics[i])

# plot all the learning rates
plt.plot(learning_rates)

plt.legend([
            'train loss', 
            # 'train accuracy', 
            # 'train precision', 'train recall',
            'train f1',
            'test loss', 
            # 'test accuracy', 
            # 'test precision', 'test recall', 
            'test f1',
            'learning rates'
            ])
plt.show()

# abnormal_batches = [[10427, 7685, 10288, 8303, 2707, 6793, 6883, 11040, 6914, 2031, 2462, 8047, 6209, 1774, 10049, 9738, 7025, 7250, 799, 10314, 579, 2967, 547, 2750, 2073, 3427, 6236, 1882, 3849, 4799, 9301, 9935, 3292, 4457, 9553, 7013, 3691, 6685, 8997, 3720, 8448, 3304, 3983, 4678, 8478, 10660, 8399, 3269, 38, 2961, 9059, 9071, 2744, 7665, 2421, 4536, 2912, 5641, 6852, 7230, 7597, 2810, 2451, 3283, 2313, 1859, 581, 3970, 3276, 4508, 6034, 1767, 6016, 1782, 435, 10805, 10647, 10204, 5331, 476, 9772, 10779, 5696, 9331, 9514, 275, 8021, 5182, 3424, 520, 10163, 9123, 10655, 10588, 6314, 5913, 5735, 1627, 8382, 2344, 637, 8306, 8394, 1468, 2345, 7204, 8456, 3088, 4847, 5385, 1122, 6353, 5816, 2977, 332, 893, 5349, 1091, 4289, 10308, 1242, 9986, 1889, 9132, 7415, 10073, 7267], [6683, 941, 1099, 2672, 7100, 10983, 4762, 10964, 9782, 10026, 6583, 7362, 7667, 6600, 8090, 7637, 799, 5835, 4747, 10501, 566, 7485, 9770, 6893, 72, 8671, 10150, 7102, 5232, 10440, 8798, 1306, 9759, 7374, 5124, 7514, 7401, 2598, 10582, 3423, 2748, 5196, 7927, 10839, 2117, 11027, 6425, 805, 7068, 4892, 9462, 2982, 850, 2881, 8240, 9255, 9775, 3712, 7605, 4667, 6476, 4428, 10445, 650, 2756, 9870, 7695, 1859, 2924, 5081, 4341, 9867, 9448, 2072, 4238, 6211, 7826, 3224, 8616, 1716, 14, 9500, 8267, 4604, 7890, 5464, 1380, 2376, 8159, 2482, 8883, 177, 763, 4584, 1769, 8557, 12, 8097, 5591, 3485, 2135, 10951, 3765, 982, 9326, 3983, 10155, 4395, 10924, 8323, 257, 1575, 10464, 1367, 4293, 5145, 10699, 10564, 1811, 6932, 4127, 4219, 1783, 4208, 1432, 8668, 4171, 7676, 9648, 1312, 7887, 11118, 4536, 9533, 1093, 8639, 11060, 580, 979, 8836, 4570, 2850, 4545, 1199, 100, 9993, 2226, 3703, 3426, 6638, 2869, 833, 7777, 6307, 3890, 10508, 5205, 1942, 6399, 5247, 9059, 4630, 9857, 5170, 8478, 7889, 3678, 5570, 2671, 5360, 1690, 4145, 4461, 6582, 2658, 7727, 116, 10911, 8299, 8208, 8350, 7745, 2818, 9566, 3681, 8597, 6062, 9318, 2269, 6091, 1337, 9733, 6894, 3435, 2292, 9000, 7383, 11005, 2310, 5683, 1319, 1071, 397, 2951, 9033, 3658, 6956, 5634, 2421, 8132, 2806, 5980, 4274, 4576, 9637, 706, 3858, 1615, 11116, 4908, 1209, 6342, 6339, 6626, 1595, 10942, 9933, 9602, 4836, 9354, 440, 4376, 9044, 6883, 6694, 10606, 6096, 10936, 6313, 7032, 8346, 6030, 5671, 166, 1895, 8953, 4512, 7150, 7201, 2628, 1409, 6200, 10180, 8768], [10025, 4577, 5460, 8211, 3502, 4838, 2143, 2292, 9424, 8493, 7474, 8686, 9516, 3864, 5593, 833, 675, 5911, 3925, 1165, 1120, 7369, 5723, 7849, 4440, 6963, 7627, 1156, 1523, 2016, 9289, 2097, 5453, 4435, 9136, 1409, 9463, 2881, 10219, 4542, 8119, 2391, 3765, 5040, 6206, 8262, 6437, 8051, 9118, 8798, 1859, 9662, 3807, 10492, 5909, 9438, 8353, 2246, 9488, 3723, 9472, 865, 8212, 8886, 9301, 7704, 5544, 570, 9588, 7955, 6531, 2897, 5298, 2811, 9334, 1987, 6370, 10082, 1821, 13, 307, 6640, 507, 4409, 10525, 2864, 8120, 805, 3681, 10810, 9647, 1407, 3191, 3393, 841, 1774, 7540, 720, 5145, 4003, 10075, 3100, 4462, 7170, 9745, 3513, 10453, 4737, 8360, 1897, 4001, 6228, 2899, 7481, 7076, 1174, 1309, 5548, 1913, 4367, 7464, 8134, 9821, 11060, 7038, 7194, 7904, 3575, 8439, 10920, 5119, 8278, 8555, 6093, 4563, 5528, 939, 10150, 2852, 7936, 10259, 4589, 5431, 1439, 10172, 4156, 6805, 9205, 8305, 10283, 1500, 9383, 3768, 1376, 8768, 5265, 1124, 9614, 6630, 2211, 10305, 6185, 2932, 8586, 3536, 5888, 7215, 7055, 4171, 3551, 6371, 1584, 4904, 9918, 3818, 37, 1399, 10885, 6757, 2250, 4558, 10988, 7150, 3094, 3435, 580, 10482, 4857, 2521, 9916, 673, 9864, 2754, 9163, 6183, 7201, 3143, 9494, 806, 10921, 10301, 7670, 2498, 1019, 4518, 10397, 11070, 852, 7765, 4529, 3745, 3951, 3760, 7726, 763, 5299, 3334, 2943, 7713, 1074, 5771, 3876, 9036, 6641, 9147, 5994, 1964, 6075, 7214, 6884, 6158, 1180, 3522, 8455, 7746, 6129, 7500, 3582, 9623, 9968, 3966, 9972, 4600, 3980, 6124, 3105, 4504, 4654, 7884, 4514, 2040, 5821, 959, 1655, 1835, 414, 5132, 8184, 1630, 1371, 4366, 5139, 1504, 5030, 4936, 9693, 2147, 3532, 527, 6797, 4259, 9618, 4736, 5549, 2076, 10652, 10544, 5570, 8281, 4449, 6781, 8159, 2622, 519, 6996, 6575, 1475, 9935, 5478, 463, 10262, 5979, 3419, 2956, 11102, 6399, 10421, 7666, 7889, 2785, 7695, 735, 449, 6718, 9613, 5832, 4502, 2421, 1075, 1282, 8017, 873, 4334, 6684, 10934, 2126, 4535, 10008], [3944, 4802, 10971, 7986, 3411, 5991, 4920, 9093, 3796, 1596, 3234, 6260, 5741, 5568, 5716, 141, 4585, 5430, 7069, 3, 520, 1211, 931, 137, 6784, 1352, 4049, 5736, 7451, 1975, 4678, 7429, 9012, 10377, 1483, 7622, 9962, 5012, 2678, 2578, 7216, 10328, 6456, 600, 4867, 6638, 4, 7640, 8749, 5796, 3791, 6610, 8208, 7835, 8295, 2781, 2947, 451, 284, 8188, 6168, 9131, 1008, 10373, 9637, 9402, 4466, 9535, 11046, 476, 7853, 9665, 2403, 1233, 3318, 3263, 527, 4238, 8439, 799, 7679, 5497, 3134, 1841, 4519, 3286, 8202, 7161, 9857, 5002, 4251, 10531, 9054, 9506, 10806, 8713, 10704, 2249, 4499, 9018, 4716, 3292, 4005, 7012, 9588, 7908, 1576, 10647, 5881, 1142, 803, 10670, 5, 1605, 5414, 1012, 2126, 4508, 2271, 9373, 275, 1904, 7629, 1260, 2840, 9020, 9334, 1660, 945, 977, 2421, 6519, 3623, 3875, 2091, 2315, 5249, 10814, 4907, 786, 9301, 4202, 4168, 6379, 7275, 4146, 6399, 1621, 9924, 1324, 4979, 9938, 9789, 1093, 4370, 7150, 4880, 1471, 652, 2851, 4378, 8087, 3300, 4299, 4235, 4434, 6598, 6721, 1050, 1622, 4110, 3369, 1814, 9364, 1434, 1432, 3782, 3426, 3268, 5372, 9860, 9785, 8699, 7006, 4200, 5370, 2744, 8072, 4589, 6793, 6538, 4559, 3980, 2839, 6187, 3677, 10092, 1320, 6117, 6179, 1859, 4689, 689, 2576, 176, 8969, 1046, 8975, 2624, 5259, 4916, 6728, 6945, 5793, 6047, 5811, 3011, 4212, 9618, 1513, 9147, 4001, 3506, 4531, 8643, 10093, 10237, 5964, 2076, 7785, 5944, 8522, 6803, 10659, 1419, 8163, 5289, 4006, 4226, 9116, 7282, 7907, 3157, 534, 1167, 593, 4969, 6173, 5895, 4597, 10636, 9669, 7596, 1196, 5513, 5381, 2150, 7373, 9023, 4373, 3294, 4588, 4703, 5825, 5396, 1174, 3128, 1317, 5629, 871, 5697, 8581, 8702, 283, 9768, 1625, 383, 9042, 3069, 2778, 768, 1231, 3392, 6530, 5771, 9461, 5214, 4726, 1890, 540, 6908, 4650, 10922, 10658, 1716, 2852, 742, 7140, 8030, 10368, 8656, 6837, 9335, 4331, 4375, 5498, 1179, 1246, 100, 733, 6990, 2707, 6404, 11064, 9489, 6327, 8534, 1581, 6943, 6627, 1629, 817, 6346, 4099, 4071, 3007, 3899, 4198, 2316, 7120, 4313, 10882, 637, 351, 9563, 5141, 3850, 2561, 7537, 7046, 2, 1107, 828, 10174, 8297, 11060, 10103, 6411, 253, 475, 4737, 6000, 9792, 2598, 3301, 2169, 3004, 1897, 4062, 10439, 1736, 790, 826, 1444, 7546, 5911, 4756, 1099, 10738, 7887, 10200, 5994, 6649, 5889, 2461, 840, 7554, 2057, 4044, 1665, 2527, 1282], [10090, 5232, 11060, 11109, 4023, 7251, 4184, 1575, 2421, 3908, 9130, 4900, 7962, 5596, 2634, 941, 5849, 8997, 8200, 10163, 2076, 4187, 5957, 268, 6834, 5539, 2693, 1777, 4558, 70, 3315, 2711, 10241, 8428, 2482, 4422, 8292, 9720, 5591, 5585, 7416, 7588, 7556, 1024, 4259, 1102, 8256, 10308, 595, 7658, 1219, 1546, 9782, 4221, 3676, 8568, 3426, 699, 10597, 11079, 5848, 4015, 8530, 9479, 1209, 6292, 3572, 9863, 7569, 141, 9649, 871, 9662, 10329, 2669, 5081, 2823, 50, 8980, 6437, 8632, 1085, 6050, 7737, 6433, 6608, 3132, 10957, 4870, 4720, 841, 2992, 10507, 6103, 5460, 7746, 2485, 5124, 2675, 6776, 154, 7429, 9044, 2828, 5236, 8410, 7324, 698, 9807, 4071, 489, 10715, 10485, 9962, 9619, 335, 11000, 1155, 468, 2097, 2850, 446, 8257, 10410, 7263, 10948, 7441, 4298, 4933, 5143, 4340, 10162, 3965, 2271, 8770, 5349, 5470, 7452, 9469, 7239, 8886, 5816, 5739, 440, 7947, 8457, 10234, 7361, 7877, 4429, 6094, 8373, 4724, 7189, 9667, 7372, 6837, 8488, 5505, 5073, 8581, 4964, 8512, 10259, 3015, 438, 7249, 9759, 5426, 8585, 8618, 4690, 2046, 3629, 3271, 10110, 4504, 4630, 937, 1859, 4338, 2318, 2148, 3660, 572, 9986, 1342, 7592, 4204, 1965, 7362]]
# counter = Counter()
# for cur_list in abnormal_batches:
#     counter.update(set(cur_list))
# fishy_examples = [elem for elem, count in counter.items() if count >= 3]
# print(fishy_examples)

# all_data = MyDataset([',', '\t'], ['data/kaggle spam.csv', 'data/UC Irvine collection/SMSSpamCollection'])
# for i in fishy_examples:
#     print(f'{all_data[i][2]}, {all_data[i][3]}')